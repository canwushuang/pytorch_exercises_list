{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2.PyTorch自動微分.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOyjqnN3PJs2nljhBJ5j0bH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"fco0occ5_gBz"},"source":["autograd 包是 PyTorch 中所有神经网络的核心。首先让我们简要地介绍它，然后我们将会去训练我们的第一个神经网络。该 autograd 软件包为 Tensors 上的所有操作提供自动微分。它是一个由运行定义的框架，这意味着以代码运行方式定义你的后向传播，并且每次迭代都可以不同。我们从 tensor 和 gradients 来举一些例子。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j7T5Z3eV_g_b","executionInfo":{"status":"ok","timestamp":1632725015114,"user_tz":-480,"elapsed":4329,"user":{"displayName":"Liao Jack","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16157886839679822522"}},"outputId":"33634877-484c-4dbc-9621-e7a5a13700dd"},"source":["import torch\n","\n","x = torch.ones(2, 2, requires_grad=True)\n","x"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 1.],\n","        [1., 1.]], requires_grad=True)"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RiUru6KI_pIU","executionInfo":{"status":"ok","timestamp":1632725204089,"user_tz":-480,"elapsed":371,"user":{"displayName":"Liao Jack","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16157886839679822522"}},"outputId":"d81211a6-1051-4d4e-a378-079232281e74"},"source":["y = x + 2\n","y"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[3., 3.],\n","        [3., 3.]], grad_fn=<AddBackward0>)"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KKSwJi7QAXUS","executionInfo":{"status":"ok","timestamp":1632725213301,"user_tz":-480,"elapsed":233,"user":{"displayName":"Liao Jack","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16157886839679822522"}},"outputId":"8d37e6e0-ebfd-4ffd-bf7d-2d133bc914af"},"source":["#y 作为操作的结果被创建，所以它有 grad_fn\n","y.grad_fn"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<AddBackward0 at 0x7f44827c22d0>"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8aAcIPqFAb4S","executionInfo":{"status":"ok","timestamp":1632725237849,"user_tz":-480,"elapsed":240,"user":{"displayName":"Liao Jack","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16157886839679822522"}},"outputId":"2685e4dc-81a3-4621-f041-be94b3b85fc5"},"source":["z = y * y * 3\n","out = z.mean()\n","z, out"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[27., 27.],\n","         [27., 27.]], grad_fn=<MulBackward0>),\n"," tensor(27., grad_fn=<MeanBackward0>))"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m3CngKq4Ajil","executionInfo":{"status":"ok","timestamp":1632725271968,"user_tz":-480,"elapsed":229,"user":{"displayName":"Liao Jack","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16157886839679822522"}},"outputId":"54ab1eca-1ad7-4b59-cc11-baae4c7edf17"},"source":["out.backward()\n","x.grad"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[4.5000, 4.5000],\n","        [4.5000, 4.5000]])"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5o4bVKFAAtJ9","executionInfo":{"status":"ok","timestamp":1632725304906,"user_tz":-480,"elapsed":241,"user":{"displayName":"Liao Jack","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16157886839679822522"}},"outputId":"21a06eb9-a8d6-4b46-eb2e-a7b66c2ec0cc"},"source":["#现在让我们看一个雅可比向量积的例子\n","x = torch.randn(3, requires_grad=True)\n","\n","y = x * 2\n","while y.data.norm() < 1000:\n","    y = y * 2\n","\n","y"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-1490.7324,   805.5214,   250.0746], grad_fn=<MulBackward0>)"]},"metadata":{},"execution_count":6}]}]}