{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"13.10. 实战 Kaggle 比赛：狗的品种识别（ImageNet Dogs）.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPBcWAdcSsRO+F3vEfKqpqo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"b5naW4AQsN4J"},"source":["!pip install d2l\n","import os\n","import torch\n","import torchvision\n","from torch import nn\n","from d2l import torch as d2l"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k6W8-qzlsWqA"},"source":["# 同样，为了便于入门，我们提供完整数据集的小规模样本：train_valid_test_tiny.zip。 \n","#如果你要在 Kaggle 比赛中使用完整的数据集，则需要将下面的 demo 变量更改为 False。\n","d2l.DATA_HUB['dog_tiny'] = (d2l.DATA_URL + 'kaggle_dog_tiny.zip',\n","                            '0cb91d09b814ecdc07b50f31f8dcad3e81d6a86d')\n","\n","# 如果你使用Kaggle比赛的完整数据集，请将下面的变量更改为False\n","demo = True\n","if demo:\n","    data_dir = d2l.download_extract('dog_tiny')\n","else:\n","    data_dir = os.path.join('..', 'data', 'dog-breed-identification')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OTmqO-Pdsc4L"},"source":["#13.10.1.2. 整理数据集\n","#我们可以像 13.9节 中所做的那样整理数据集，即从原始训练集中拆分验证集，然后将图像移动到按标签分组的子文件夹中。\n","#下面的 reorg_dog_data 函数读取训练数据标签、拆分验证集并整理训练集。\n","def reorg_dog_data(data_dir, valid_ratio):\n","    labels = d2l.read_csv_labels(os.path.join(data_dir, 'labels.csv'))\n","    d2l.reorg_train_valid(data_dir, labels, valid_ratio)\n","    d2l.reorg_test(data_dir)\n","\n","batch_size = 32 if demo else 128\n","valid_ratio = 0.1\n","reorg_dog_data(data_dir, valid_ratio)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wSgm8nJAsc5Y"},"source":["#13.10.2. 图像增广\n","#回想一下，这个狗品种数据集是 ImageNet 数据集的子集，其图像大于 13.9节 中 CIFAR-10 数据集的图像。 \n","#下面我们看一下如何在相对较大的图像上使用图像增广。\n","transform_train = torchvision.transforms.Compose([\n","    # 随机裁剪图像，所得图像为原始面积的0.08到1之间，高宽比在3/4和4/3之间。\n","    # 然后，缩放图像以创建224 x 224的新图像\n","    torchvision.transforms.RandomResizedCrop(224, scale=(0.08, 1.0),\n","                                             ratio=(3.0 / 4.0, 4.0 / 3.0)),\n","    torchvision.transforms.RandomHorizontalFlip(),\n","    # 随机更改亮度，对比度和饱和度\n","    torchvision.transforms.ColorJitter(brightness=0.4, contrast=0.4,\n","                                       saturation=0.4),\n","    # 添加随机噪声\n","    torchvision.transforms.ToTensor(),\n","    # 标准化图像的每个通道\n","    torchvision.transforms.Normalize([0.485, 0.456, 0.406],\n","                                     [0.229, 0.224, 0.225])])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lc8KJZYJsoDA"},"source":["#测试时，我们只使用确定性的图像预处理操作。\n","transform_test = torchvision.transforms.Compose([\n","    torchvision.transforms.Resize(256),\n","    # 从图像中心裁切224x224大小的图片\n","    torchvision.transforms.CenterCrop(224),\n","    torchvision.transforms.ToTensor(),\n","    torchvision.transforms.Normalize([0.485, 0.456, 0.406],\n","                                     [0.229, 0.224, 0.225])])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w24t00-BspiG"},"source":["#13.10.3. 读取数据集\n","#与 13.9节 一样，我们可以读取整理后的含原始图像文件的数据集。\n","train_ds, train_valid_ds = [\n","    torchvision.datasets.ImageFolder(\n","        os.path.join(data_dir, 'train_valid_test', folder),\n","        transform=transform_train) for folder in ['train', 'train_valid']]\n","\n","valid_ds, test_ds = [\n","    torchvision.datasets.ImageFolder(\n","        os.path.join(data_dir, 'train_valid_test', folder),\n","        transform=transform_test) for folder in ['valid', 'test']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nr5EN-zIst5t"},"source":["#下面我们创建数据加载器实例的方式与 13.9节 相同。\n","train_iter, train_valid_iter = [\n","    torch.utils.data.DataLoader(dataset, batch_size, shuffle=True,\n","                                drop_last=True)\n","    for dataset in (train_ds, train_valid_ds)]\n","\n","valid_iter = torch.utils.data.DataLoader(valid_ds, batch_size, shuffle=False,\n","                                         drop_last=True)\n","\n","test_iter = torch.utils.data.DataLoader(test_ds, batch_size, shuffle=False,\n","                                        drop_last=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZdTSL4WLvMSm"},"source":["#13.10.4. 微调预训练模型\n","#回想一下，我们使用三个 RGB 通道的均值和标准差来对完整的 ImageNet 数据集进行图像标准化。 \n","#事实上，这也符合 ImageNet 上预训练模型的标准化操作。\n","def get_net(devices):\n","    finetune_net = nn.Sequential()\n","    finetune_net.features = torchvision.models.resnet34(pretrained=True)\n","    # 定义一个新的输出网络，共有120个输出类别\n","    finetune_net.output_new = nn.Sequential(nn.Linear(1000, 256), nn.ReLU(),\n","                                            nn.Linear(256, 120))\n","    # 将模型参数分配给用于计算的CPU或GPU\n","    finetune_net = finetune_net.to(devices[0])\n","    # 冻结参数\n","    for param in finetune_net.features.parameters():\n","        param.requires_grad = False\n","    return finetune_net"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2lUWM5TTvSlp"},"source":["#在计算损失之前，我们首先获取预训练模型的输出层的输入，即提取的特征。然后我们使用此特征作为我们小型自定义输出网络的输入来计算损失。\n","loss = nn.CrossEntropyLoss(reduction='none')\n","\n","def evaluate_loss(data_iter, net, devices):\n","    l_sum, n = 0.0, 0\n","    for features, labels in data_iter:\n","        features, labels = features.to(devices[0]), labels.to(devices[0])\n","        outputs = net(features)\n","        l = loss(outputs, labels)\n","        l_sum += l.sum()\n","        n += labels.numel()\n","    return l_sum / n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EttIZgejvYGj"},"source":["#13.10.5. 定义训练函数\n","#我们将根据模型在验证集上的表显选择模型并调整超参数。模型训练函数 train 只迭代小型自定义输出网络的参数。\n","def train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period,\n","          lr_decay):\n","    # 只训练小型自定义输出网络\n","    net = nn.DataParallel(net, device_ids=devices).to(devices[0])\n","    trainer = torch.optim.SGD(\n","        (param for param in net.parameters() if param.requires_grad), lr=lr,\n","        momentum=0.9, weight_decay=wd)\n","    scheduler = torch.optim.lr_scheduler.StepLR(trainer, lr_period, lr_decay)\n","    num_batches, timer = len(train_iter), d2l.Timer()\n","    legend = ['train loss']\n","    if valid_iter is not None:\n","        legend.append('valid loss')\n","    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],\n","                            legend=legend)\n","    for epoch in range(num_epochs):\n","        metric = d2l.Accumulator(2)\n","        for i, (features, labels) in enumerate(train_iter):\n","            timer.start()\n","            features, labels = features.to(devices[0]), labels.to(devices[0])\n","            trainer.zero_grad()\n","            output = net(features)\n","            l = loss(output, labels).sum()\n","            l.backward()\n","            trainer.step()\n","            metric.add(l, labels.shape[0])\n","            timer.stop()\n","            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n","                animator.add(epoch + (i + 1) / num_batches,\n","                             (metric[0] / metric[1], None))\n","        measures = f'train loss {metric[0] / metric[1]:.3f}'\n","        if valid_iter is not None:\n","            valid_loss = evaluate_loss(valid_iter, net, devices)\n","            animator.add(epoch + 1, (None, valid_loss.detach()))\n","        scheduler.step()\n","    if valid_iter is not None:\n","        measures += f', valid loss {valid_loss:.3f}'\n","    print(measures + f'\\n{metric[1] * num_epochs / timer.sum():.1f}'\n","          f' examples/sec on {str(devices)}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0OyQf7WIvdG7"},"source":["#13.10.6. 训练和验证模型\n","#现在我们可以训练和验证模型了，以下超参数都是可调的。 \n","#例如，可以增加迭代周期：由于 lr_period 和 lr_decay 分别设置为 2 和 0.9，因此优化算法的学习速率将在每 2 个迭代后乘以 0.9。\n","devices, num_epochs, lr, wd = d2l.try_all_gpus(), 10, 1e-4, 1e-4\n","lr_period, lr_decay, net = 2, 0.9, get_net(devices)\n","train(net, train_iter, valid_iter, num_epochs, lr, wd, devices, lr_period,\n","      lr_decay)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ryjqm16ovjX5"},"source":["#13.10.7. 对测试集分类并在 Kaggle 提交结果\n","#与 13.9节 中的最后一步类似，最终所有标记的数据（包括验证集）都用于训练模型和对测试集进行分类。 我们将使用训练好的自定义输出网络进行分类。\n","net = get_net(devices)\n","train(net, train_valid_iter, None, num_epochs, lr, wd, devices, lr_period,\n","      lr_decay)\n","\n","preds = []\n","for data, label in test_iter:\n","    output = torch.nn.functional.softmax(net(data.to(devices[0])), dim=0)\n","    preds.extend(output.cpu().detach().numpy())\n","ids = sorted(\n","    os.listdir(os.path.join(data_dir, 'train_valid_test', 'test', 'unknown')))\n","with open('submission.csv', 'w') as f:\n","    f.write('id,' + ','.join(train_valid_ds.classes) + '\\n')\n","    for i, output in zip(ids, preds):\n","        f.write(\n","            i.split('.')[0] + ',' + ','.join([str(num)\n","                                              for num in output]) + '\\n')"],"execution_count":null,"outputs":[]}]}