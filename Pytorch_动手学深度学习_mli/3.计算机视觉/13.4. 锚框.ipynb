{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"13.4. 锚框.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOACt5Kzt7UN0ElIg3pAEiM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"Ijnw3Ba3w9Do"},"source":["#目标检测算法通常会在输入图像中采样大量的区域，然后判断这些区域中是否包含我们感兴趣的目标，\n","#并调整区域边缘从而更准确地预测目标的真实边界框（ground-truth bounding box）。 \n","#不同的模型使用的区域采样方法可能不同。 \n","#这里我们介绍其中的一种方法：它以每个像素为中心生成多个大小和宽高比（aspect ratio）不同的边界框。 \n","#这些边界框被称为锚框（anchor box）我们将在 13.7节 中基于锚框设计一个目标检测模型。\n","#首先，让我们修改打印精度，以获得更简洁的输出。\n","!pip install d2l\n","%matplotlib inline\n","import torch\n","from d2l import torch as d2l\n","\n","torch.set_printoptions(2)  # 精简打印精度"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_6qplXSqxMzm"},"source":["#13.4.1. 生成多个锚框\n","def multibox_prior(data, sizes, ratios):\n","    \"\"\"生成以每个像素为中心具有不同形状的锚框。\"\"\"\n","    in_height, in_width = data.shape[-2:]\n","    device, num_sizes, num_ratios = data.device, len(sizes), len(ratios)\n","    boxes_per_pixel = (num_sizes + num_ratios - 1)\n","    size_tensor = torch.tensor(sizes, device=device)\n","    ratio_tensor = torch.tensor(ratios, device=device)\n","\n","    # 为了将锚点移动到像素的中心，需要设置偏移量。\n","    # 因为一个像素的的高为1且宽为1，我们选择偏移我们的中心0.5\n","    offset_h, offset_w = 0.5, 0.5\n","    steps_h = 1.0 / in_height  # Scaled steps in y axis\n","    steps_w = 1.0 / in_width  # Scaled steps in x axis\n","\n","    # 生成锚框的所有中心点\n","    center_h = (torch.arange(in_height, device=device) + offset_h) * steps_h\n","    center_w = (torch.arange(in_width, device=device) + offset_w) * steps_w\n","    shift_y, shift_x = torch.meshgrid(center_h, center_w)\n","    shift_y, shift_x = shift_y.reshape(-1), shift_x.reshape(-1)\n","\n","    # 生成“boxes_per_pixel”个高和宽，\n","    # 之后用于创建锚框的四角坐标 (xmin, xmax, ymin, ymax)\n","    w = torch.cat((size_tensor * torch.sqrt(ratio_tensor[0]),\n","                   sizes[0] * torch.sqrt(ratio_tensor[1:])))\\\n","                   * in_height / in_width  # Handle rectangular inputs\n","    h = torch.cat((size_tensor / torch.sqrt(ratio_tensor[0]),\n","                   sizes[0] / torch.sqrt(ratio_tensor[1:])))\n","    # 除以2来获得半高和半宽\n","    anchor_manipulations = torch.stack(\n","        (-w, -h, w, h)).T.repeat(in_height * in_width, 1) / 2\n","\n","    # 每个中心点都将有“boxes_per_pixel”个锚框，\n","    # 所以生成含所有锚框中心的网格，重复了“boxes_per_pixel”次\n","    out_grid = torch.stack([shift_x, shift_y, shift_x, shift_y],\n","                           dim=1).repeat_interleave(boxes_per_pixel, dim=0)\n","    output = out_grid + anchor_manipulations\n","    return output.unsqueeze(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EDlb8Yf8xM0_"},"source":["#我们可以看到返回的锚框变量 Y 的形状是（批量大小，锚框的数量，4）。\n","img = d2l.plt.imread('../img/catdog.jpg')\n","h, w = img.shape[:2]\n","\n","print(h, w)\n","X = torch.rand(size=(1, 3, h, w))\n","Y = multibox_prior(X, sizes=[0.75, 0.5, 0.25], ratios=[1, 2, 0.5])\n","Y.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YIEMgTUrxXoC"},"source":["#在接下来的内容中，我们访问以 (250, 250) 为中心的第一个锚框。 它有四个元素：锚框左上角的  (x,y)  轴坐标和右下角的  (x,y)  轴坐标。 \n","#将两个轴的坐标分别除以图像的宽度和高度后，所得的值就介于 0 和 1 之间。\n","boxes = Y.reshape(h, w, 5, 4)\n","boxes[250, 250, 0, :]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FI_QlIRmxez6"},"source":["#为了显示以图像中一个像素为中心的所有锚框，我们定义了以下 show_bboxes 函数来在图像上绘制多个边界框。\n","def show_bboxes(axes, bboxes, labels=None, colors=None):\n","    \"\"\"显示所有边界框。\"\"\"\n","    def _make_list(obj, default_values=None):\n","        if obj is None:\n","            obj = default_values\n","        elif not isinstance(obj, (list, tuple)):\n","            obj = [obj]\n","        return obj\n","\n","    labels = _make_list(labels)\n","    colors = _make_list(colors, ['b', 'g', 'r', 'm', 'c'])\n","    for i, bbox in enumerate(bboxes):\n","        color = colors[i % len(colors)]\n","        rect = d2l.bbox_to_rect(bbox.detach().numpy(), color)\n","        axes.add_patch(rect)\n","        if labels and len(labels) > i:\n","            text_color = 'k' if color == 'w' else 'w'\n","            axes.text(rect.xy[0], rect.xy[1], labels[i], va='center',\n","                      ha='center', fontsize=9, color=text_color,\n","                      bbox=dict(facecolor=color, lw=0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6yP7iFD0xe08"},"source":["#正如我们刚才看到的，变量 boxes 中  x  轴和  y  轴的坐标值已分别除以图像的宽度和高度。 \n","#绘制锚框时，我们需要恢复它们原始的坐标值。 因此，我们在下面定义了变量 bbox_scale 。 \n","#现在，我们可以绘制出图像中所有以（250、250）为中心的锚框了。 如下所示，尺度为 0.75 且宽高比为 1 的蓝色锚框很好地围绕着图像中的狗。\n","d2l.set_figsize()\n","bbox_scale = torch.tensor((w, h, w, h))\n","fig = d2l.plt.imshow(img)\n","show_bboxes(fig.axes, boxes[250, 250, :, :] * bbox_scale, [\n","    's=0.75, r=1', 's=0.5, r=1', 's=0.25, r=1', 's=0.75, r=2', 's=0.75, r=0.5'\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J1iMnXgVxtzU"},"source":["#13.4.2. 交并比(IoU)\n","#事实上，我们可以将任何边界框的像素区域视为一组像素。通 过这种方式，我们可以通过其像素集的 Jaccard 索引来测量两个边界框的相似性。 \n","#对于两个边界框，我们通常将他们的 Jaccard 指数称为 交并比 (intersection over union，IoU)，即两个边界框相交面积与相并面积之比，如 图13.4.1 所示。 \n","#交并比的取值范围在0和1之间：0表示两个边界框无重合像素，1表示两个边界框完全重合。\n","def box_iou(boxes1, boxes2):\n","    \"\"\"计算两个锚框或边界框列表中成对的交并比。\"\"\"\n","    box_area = lambda boxes: ((boxes[:, 2] - boxes[:, 0]) *\n","                              (boxes[:, 3] - boxes[:, 1]))\n","    # `boxes1`, `boxes2`, `areas1`, `areas2`的形状:\n","    # `boxes1`：(boxes1的数量, 4),\n","    # `boxes2`：(boxes2的数量, 4),\n","    # `areas1`：(boxes1的数量,),\n","    # `areas2`：(boxes2的数量,)\n","    areas1 = box_area(boxes1)\n","    areas2 = box_area(boxes2)\n","    #  `inter_upperlefts`, `inter_lowerrights`, `inters`的形状:\n","    # (boxes1的数量, boxes2的数量, 2)\n","    inter_upperlefts = torch.max(boxes1[:, None, :2], boxes2[:, :2])\n","    inter_lowerrights = torch.min(boxes1[:, None, 2:], boxes2[:, 2:])\n","    inters = (inter_lowerrights - inter_upperlefts).clamp(min=0)\n","    # `inter_areas` and `union_areas`的形状: (boxes1的数量, boxes2的数量)\n","    inter_areas = inters[:, :, 0] * inters[:, :, 1]\n","    union_areas = areas1[:, None] + areas2 - inter_areas\n","    return inter_areas / union_areas"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6tznEo44x8a0"},"source":["#13.4.3.1. 将真实边界框分配给锚框\n","#此算法在以下 assign_anchor_to_bbox 函数中实现。\n","def assign_anchor_to_bbox(ground_truth, anchors, device, iou_threshold=0.5):\n","    \"\"\"将最接近的真实边界框分配给锚框。\"\"\"\n","    num_anchors, num_gt_boxes = anchors.shape[0], ground_truth.shape[0]\n","    # 位于第i行和第j列的元素 x_ij 是锚框i和真实边界框j的IoU\n","    jaccard = box_iou(anchors, ground_truth)\n","    # 对于每个锚框，分配的真实边界框的张量\n","    anchors_bbox_map = torch.full((num_anchors,), -1, dtype=torch.long,\n","                                  device=device)\n","    # 根据阈值，决定是否分配真实边界框\n","    max_ious, indices = torch.max(jaccard, dim=1)\n","    anc_i = torch.nonzero(max_ious >= 0.5).reshape(-1)\n","    box_j = indices[max_ious >= 0.5]\n","    anchors_bbox_map[anc_i] = box_j\n","    col_discard = torch.full((num_anchors,), -1)\n","    row_discard = torch.full((num_gt_boxes,), -1)\n","    for _ in range(num_gt_boxes):\n","        max_idx = torch.argmax(jaccard)\n","        box_idx = (max_idx % num_gt_boxes).long()\n","        anc_idx = (max_idx / num_gt_boxes).long()\n","        anchors_bbox_map[anc_idx] = box_idx\n","        jaccard[:, box_idx] = col_discard\n","        jaccard[anc_idx, :] = row_discard\n","    return anchors_bbox_map"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wwkRYO32yHUV"},"source":["#13.4.3.2. 标记类和偏移\n","def offset_boxes(anchors, assigned_bb, eps=1e-6):\n","    \"\"\"对锚框偏移量的转换。\"\"\"\n","    c_anc = d2l.box_corner_to_center(anchors)\n","    c_assigned_bb = d2l.box_corner_to_center(assigned_bb)\n","    offset_xy = 10 * (c_assigned_bb[:, :2] - c_anc[:, :2]) / c_anc[:, 2:]\n","    offset_wh = 5 * torch.log(eps + c_assigned_bb[:, 2:] / c_anc[:, 2:])\n","    offset = torch.cat([offset_xy, offset_wh], axis=1)\n","    return offset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JDRLRV6qyHVf"},"source":["def multibox_target(anchors, labels):\n","    \"\"\"使用真实边界框标记锚框。\"\"\"\n","    batch_size, anchors = labels.shape[0], anchors.squeeze(0)\n","    batch_offset, batch_mask, batch_class_labels = [], [], []\n","    device, num_anchors = anchors.device, anchors.shape[0]\n","    for i in range(batch_size):\n","        label = labels[i, :, :]\n","        anchors_bbox_map = assign_anchor_to_bbox(label[:, 1:], anchors,\n","                                                 device)\n","        bbox_mask = ((anchors_bbox_map >= 0).float().unsqueeze(-1)).repeat(\n","            1, 4)\n","        # 将类标签和分配的边界框坐标初始化为零\n","        class_labels = torch.zeros(num_anchors, dtype=torch.long,\n","                                   device=device)\n","        assigned_bb = torch.zeros((num_anchors, 4), dtype=torch.float32,\n","                                  device=device)\n","        # 使用真实边界框来标记锚框的类别。\n","        # 如果一个锚框没有被分配，我们标记其为背景（值为零）\n","        indices_true = torch.nonzero(anchors_bbox_map >= 0)\n","        bb_idx = anchors_bbox_map[indices_true]\n","        class_labels[indices_true] = label[bb_idx, 0].long() + 1\n","        assigned_bb[indices_true] = label[bb_idx, 1:]\n","        # 偏移量转换\n","        offset = offset_boxes(anchors, assigned_bb) * bbox_mask\n","        batch_offset.append(offset.reshape(-1))\n","        batch_mask.append(bbox_mask.reshape(-1))\n","        batch_class_labels.append(class_labels)\n","    bbox_offset = torch.stack(batch_offset)\n","    bbox_mask = torch.stack(batch_mask)\n","    class_labels = torch.stack(batch_class_labels)\n","    return (bbox_offset, bbox_mask, class_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EeYIeeFUyYFy"},"source":["#13.4.3.3. 一个例子\n","#让我们通过一个具体的例子来说明锚箱标签。 \n","#我们在加载的图像中为狗和猫定义了地面真实边界框，其中第一个元素是类（0 代表狗，1 代表猫），\n","#其余四个元素是左上角和右下角的  (x,y)  轴坐标（范围介于 0 和 1 之间）。 \n","#我们还构建了五个锚框，用左上角和右下角的坐标进行标记： A0,…,A4 （索引从 0 开始）。 然后我们在图像中绘制这些地面真相边界框和锚框。\n","ground_truth = torch.tensor([[0, 0.1, 0.08, 0.52, 0.92],\n","                             [1, 0.55, 0.2, 0.9, 0.88]])\n","anchors = torch.tensor([[0, 0.1, 0.2, 0.3], [0.15, 0.2, 0.4, 0.4],\n","                        [0.63, 0.05, 0.88, 0.98], [0.66, 0.45, 0.8, 0.8],\n","                        [0.57, 0.3, 0.92, 0.9]])\n","\n","fig = d2l.plt.imshow(img)\n","show_bboxes(fig.axes, ground_truth[:, 1:] * bbox_scale, ['dog', 'cat'], 'k')\n","show_bboxes(fig.axes, anchors * bbox_scale, ['0', '1', '2', '3', '4']);"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HtpvZHAcygek"},"source":["#使用上面定义的 multibox_target 函数，我们可以根据狗和猫的真实边界框，标注这些锚框的分类和偏移量。 \n","#在这个例子中，背景、狗和猫的类索引分别为 0、1 和 2。 下面我们为锚框和真实边界框范例添加了维度。\n","labels = multibox_target(anchors.unsqueeze(dim=0),\n","                         ground_truth.unsqueeze(dim=0))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EQbfoG-Uym8t"},"source":["#13.4.4. 使用非极大值抑制预测边界框\n","#在预测期间，我们先为图像生成多个锚框，再为这些锚框一一预测类别和偏移量。 \n","#一个“预测好的边界框”就根据带有预测偏移量的锚框就油然而生。 \n","#下面我们实现了 offset_inverse 函数，该函数将锚框和偏移量预测作为输入，并应用逆偏移变换来返回预测的边界框坐标。\n","def offset_inverse(anchors, offset_preds):\n","    \"\"\"根据带有预测偏移量的锚框来预测边界框。\"\"\"\n","    anc = d2l.box_corner_to_center(anchors)\n","    pred_bbox_xy = (offset_preds[:, :2] * anc[:, 2:] / 10) + anc[:, :2]\n","    pred_bbox_wh = torch.exp(offset_preds[:, 2:] / 5) * anc[:, 2:]\n","    pred_bbox = torch.cat((pred_bbox_xy, pred_bbox_wh), axis=1)\n","    predicted_bbox = d2l.box_center_to_corner(pred_bbox)\n","    return predicted_bbox"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EBAB5GFvyuXV"},"source":["#以下 nms 函数按降序对置信度进行排序并返回其索引。\n","def nms(boxes, scores, iou_threshold):\n","    \"\"\"对预测边界框的置信度进行排序。\"\"\"\n","    B = torch.argsort(scores, dim=-1, descending=True)\n","    keep = []  # 保留预测边界框的指标\n","    while B.numel() > 0:\n","        i = B[0]\n","        keep.append(i)\n","        if B.numel() == 1: break\n","        iou = box_iou(boxes[i, :].reshape(-1, 4),\n","                      boxes[B[1:], :].reshape(-1, 4)).reshape(-1)\n","        inds = torch.nonzero(iou <= iou_threshold).reshape(-1)\n","        B = B[inds + 1]\n","    return torch.tensor(keep, device=boxes.device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ozaCJplOyytA"},"source":["#我们定义以下 multibox_detection 函数来将非极大值抑制应用于预测边界框。 \n","#如果你发现实现有点复杂，请不要担心：我们将在实现之后，马上用一个具体的示例来展示它是如何工作的。\n","#@save\n","def multibox_detection(cls_probs, offset_preds, anchors, nms_threshold=0.5,\n","                       pos_threshold=0.009999999):\n","    \"\"\"使用非极大值抑制来预测边界框。\"\"\"\n","    device, batch_size = cls_probs.device, cls_probs.shape[0]\n","    anchors = anchors.squeeze(0)\n","    num_classes, num_anchors = cls_probs.shape[1], cls_probs.shape[2]\n","    out = []\n","    for i in range(batch_size):\n","        cls_prob, offset_pred = cls_probs[i], offset_preds[i].reshape(-1, 4)\n","        conf, class_id = torch.max(cls_prob[1:], 0)\n","        predicted_bb = offset_inverse(anchors, offset_pred)\n","        keep = nms(predicted_bb, conf, nms_threshold)\n","\n","        # 找到所有的 non_keep 索引，并将类设置为背景\n","        all_idx = torch.arange(num_anchors, dtype=torch.long, device=device)\n","        combined = torch.cat((keep, all_idx))\n","        uniques, counts = combined.unique(return_counts=True)\n","        non_keep = uniques[counts == 1]\n","        all_id_sorted = torch.cat((keep, non_keep))\n","        class_id[non_keep] = -1\n","        class_id = class_id[all_id_sorted]\n","        conf, predicted_bb = conf[all_id_sorted], predicted_bb[all_id_sorted]\n","        # `pos_threshold` 是一个用于非背景预测的阈值\n","        below_min_idx = (conf < pos_threshold)\n","        class_id[below_min_idx] = -1\n","        conf[below_min_idx] = 1 - conf[below_min_idx]\n","        pred_info = torch.cat(\n","            (class_id.unsqueeze(1), conf.unsqueeze(1), predicted_bb), dim=1)\n","        out.append(pred_info)\n","    return torch.stack(out)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1RlisZVJy2_B"},"source":["#现在让我们将上述算法应用到一个带有四个锚框的具体示例中。 \n","#为简单起见，我们假设预测的偏移量都是零，这意味着预测的边界框即是锚框。 对于背景、狗和猫其中的每个类，我们还定义了它的预测概率。\n","anchors = torch.tensor([[0.1, 0.08, 0.52, 0.92], [0.08, 0.2, 0.56, 0.95],\n","                        [0.15, 0.3, 0.62, 0.91], [0.55, 0.2, 0.9, 0.88]])\n","offset_preds = torch.tensor([0] * anchors.numel())\n","cls_probs = torch.tensor([[0] * 4,  # 背景的预测概率\n","                          [0.9, 0.8, 0.7, 0.1],  # 狗的预测概率\n","                          [0.1, 0.2, 0.3, 0.9]])  # 猫的预测概率"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0oE_6GU7y7JG"},"source":["#我们可以在图像上绘制这些预测边界框和置信度。\n","fig = d2l.plt.imshow(img)\n","show_bboxes(fig.axes, anchors * bbox_scale,\n","            ['dog=0.9', 'dog=0.8', 'dog=0.7', 'cat=0.9'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"djkLsNjey_QA"},"source":["#我们可以看到返回结果的形状是（批量大小，锚框的数量，6）。 \n","#最内层维度中的六个元素提供了同一预测边界框的输出信息。 \n","#第一个元素是预测的类索引，从 0 开始（0代表狗，1代表猫），值 -1 表示背景或在非极大值抑制中被移除了。 \n","#第二个元素是预测的边界框的置信度。 其余四个元素分别是预测边界框左上角和右下角的  (x,y)  轴坐标（范围介于 0 和 1 之间）。\n","output = multibox_detection(cls_probs.unsqueeze(dim=0),\n","                            offset_preds.unsqueeze(dim=0),\n","                            anchors.unsqueeze(dim=0), nms_threshold=0.5)\n","output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YdChITm2y_RW"},"source":["#删除 -1 （背景）类的预测边界框后，我们可以输出由非极大值抑制保存的最终预测边界框。\n","fig = d2l.plt.imshow(img)\n","for i in output[0].detach().numpy():\n","    if i[0] == -1:\n","        continue\n","    label = ('dog=', 'cat=')[int(i[0])] + str(i[1])\n","    show_bboxes(fig.axes, [torch.tensor(i[2:]) * bbox_scale], label)"],"execution_count":null,"outputs":[]}]}