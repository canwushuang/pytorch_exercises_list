{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"7.7. 稠密连接网络（DenseNet）.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMI6CmcUTtPL7y0mD3EVyCT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"v08TIJw2Z3tn"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-vBnJaA9Z6hx"},"source":["#7.7.2. 稠密块体\n","#DenseNet 使用了 ResNet 改良版的“批量归一化、激活和卷积”结构（参见 7.6节 中的练习）。 \n","#我们首先实现一下这个结构。\n","import torch\n","from torch import nn\n","from d2l import torch as d2l\n","\n","def conv_block(input_channels, num_channels):\n","    return nn.Sequential(\n","        nn.BatchNorm2d(input_channels), nn.ReLU(),\n","        nn.Conv2d(input_channels, num_channels, kernel_size=3, padding=1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wb_FuepxaAcQ"},"source":["#一个稠密块由多个卷积块组成，每个卷积块使用相同数量的输出信道。 \n","#然而，在前向传播中，我们将每个卷积块的输入和输出在通道维上连结。\n","class DenseBlock(nn.Module):\n","    def __init__(self, num_convs, input_channels, num_channels):\n","        super(DenseBlock, self).__init__()\n","        layer = []\n","        for i in range(num_convs):\n","            layer.append(\n","                conv_block(num_channels * i + input_channels, num_channels))\n","        self.net = nn.Sequential(*layer)\n","\n","    def forward(self, X):\n","        for blk in self.net:\n","            Y = blk(X)\n","            # 连接通道维度上每个块的输入和输出\n","            X = torch.cat((X, Y), dim=1)\n","        return X"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yTmGKUbyaEEi"},"source":["#在下面的例子中，我们定义一个有 2 个输出通道数为 10 的 DenseBlock。 使用通道数为 3 的输入时，我们会得到通道数为  3+2×10=23  的输出。 \n","#卷积块的通道数控制了输出通道数相对于输入通道数的增长，因此也被称为增长率（growth rate）\n","blk = DenseBlock(2, 3, 10)\n","X = torch.randn(4, 3, 8, 8)\n","Y = blk(X)\n","Y.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WZlt-GH1aHL1","executionInfo":{"status":"ok","timestamp":1619427645581,"user_tz":-480,"elapsed":1195,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}}},"source":["#7.7.3. 过渡层\n","#由于每个稠密块都会带来通道数的增加，使用过多则会过于复杂化模型。 \n","#而过渡层可以用来控制模型复杂度。 它通过  1×1  卷积层来减小通道数，\n","#并使用步幅为 2 的平均池化层减半高和宽，从而进一步降低模型复杂度。\n","def transition_block(input_channels, num_channels):\n","    return nn.Sequential(\n","        nn.BatchNorm2d(input_channels), nn.ReLU(),\n","        nn.Conv2d(input_channels, num_channels, kernel_size=1),\n","        nn.AvgPool2d(kernel_size=2, stride=2))"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"C3NOtZQ3aMAu"},"source":["#对上一个例子中稠密块的输出使用通道数为 10 的过渡层。 此时输出的通道数减为 10，高和宽均减半。\n","blk = transition_block(23, 10)\n","blk(Y).shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DyVEqkXzaP7N"},"source":["#7.7.4. DenseNet模型\n","#我们来构造 DenseNet 模型。DenseNet 首先使用同 ResNet 一样的单卷积层和最大池化层。\n","b1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\n","                   nn.BatchNorm2d(64), nn.ReLU(),\n","                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BMkiu5AhaWSK"},"source":["#在每个模块之间，ResNet 通过步幅为 2 的残差块减小高和宽，\n","#DenseNet 则使用过渡层来减半高和宽，并减半通道数。\n","# `num_channels`为当前的通道数\n","num_channels, growth_rate = 64, 32\n","num_convs_in_dense_blocks = [4, 4, 4, 4]\n","blks = []\n","for i, num_convs in enumerate(num_convs_in_dense_blocks):\n","    blks.append(DenseBlock(num_convs, num_channels, growth_rate))\n","    # 上一个稠密块的输出通道数\n","    num_channels += num_convs * growth_rate\n","    # 在稠密块之间添加一个转换层，使通道数量减半\n","    if i != len(num_convs_in_dense_blocks) - 1:\n","        blks.append(transition_block(num_channels, num_channels // 2))\n","        num_channels = num_channels // 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AP6ZPRvpaZzj"},"source":["#与 ResNet 类似，最后接上全局池化层和全连接层来输出结果。\n","net = nn.Sequential(b1, *blks, nn.BatchNorm2d(num_channels), nn.ReLU(),\n","                    nn.AdaptiveMaxPool2d((1, 1)), nn.Flatten(),\n","                    nn.Linear(num_channels, 10))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cAZuSY0Kac4R"},"source":["#7.7.5. 训练模型\n","#由于这里使用了比较深的网络，本节里我们将输入高和宽从 224 降到 96 来简化计算。\n","lr, num_epochs, batch_size = 0.1, 10, 256\n","train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\n","d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"],"execution_count":null,"outputs":[]}]}