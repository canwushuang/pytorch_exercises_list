{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5.4. 自定义层.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN7RrOWQNcyUTYPOb197u+Y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"i72yG8hOfqPX"},"source":["#5.4.1. 不带参数的层\n","#首先，我们构造一个没有任何参数的自定义层。如果你还记得我们在 5.1节 对块的介绍，\n","#这应该看起来很眼熟。下面的CenteredLayer类要从其输入中减去均值。\n","#要构建它，我们只需继承基础层类并实现正向传播功能。\n","import torch\n","import torch.nn.functional as F\n","from torch import nn\n","\n","class CenteredLayer(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, X):\n","        return X - X.mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mz8_xlgEf3Vq","executionInfo":{"status":"ok","timestamp":1619311836848,"user_tz":-480,"elapsed":3821,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}},"outputId":"cade98f4-a72b-43bc-e6fe-22624102e38e"},"source":["#让我们通过向其提供一些数据来验证该层是否按预期工作。\n","layer = CenteredLayer()\n","layer(torch.FloatTensor([1, 2, 3, 4, 5]))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([-2., -1.,  0.,  1.,  2.])"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"dNXzED3xf6PT"},"source":["#我们可以将层作为组件合并到构建更复杂的模型中。\n","net = nn.Sequential(nn.Linear(8, 128), CenteredLayer())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KNt5Z75Cf7-f","executionInfo":{"status":"ok","timestamp":1619311836850,"user_tz":-480,"elapsed":3818,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}},"outputId":"0cca93cf-157d-4edd-b253-ef08c3470014"},"source":["#作为额外的健全性检查，我们可以向网络发送随机数据后，检查均值是否为0。由于我们处理的是浮点数，\n","#因为存储精度的原因，我们仍然可能会看到一个非常小的非零数。\n","Y = net(torch.rand(4, 8))\n","Y.mean()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(5.5879e-09, grad_fn=<MeanBackward0>)"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"z1JXYoDogEsH"},"source":["#5.4.2. 带参数的图层\n","#现在，让我们实现自定义版本的全连接层。回想一下，该层需要两个参数，一个用于表示权重，\n","#另一个用于表示偏置项。在此实现中，我们使用ReLU作为激活函数。该层需要输入参数：in_units和units，分别表示输入和输出的数量。\n","class MyLinear(nn.Module):\n","    def __init__(self, in_units, units):\n","        super().__init__()\n","        self.weight = nn.Parameter(torch.randn(in_units, units))\n","        self.bias = nn.Parameter(torch.randn(units,))\n","\n","    def forward(self, X):\n","        linear = torch.matmul(X, self.weight.data) + self.bias.data\n","        return F.relu(linear)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Ef2HAtCgLo6","executionInfo":{"status":"ok","timestamp":1619311836851,"user_tz":-480,"elapsed":3814,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}},"outputId":"547086ef-d9c6-4ace-f708-2e7870129172"},"source":["#实例化MyDense类并访问其模型参数。\n","dense = MyLinear(5, 3)\n","dense.weight"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[-0.4620, -0.1337, -0.0640],\n","        [-0.8994,  2.4415,  0.2044],\n","        [ 0.0836,  0.4356,  0.7880],\n","        [-1.0027, -0.8975, -1.6845],\n","        [-0.2940,  0.5066, -0.3934]], requires_grad=True)"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zpAsq_ICgO4f","executionInfo":{"status":"ok","timestamp":1619311836851,"user_tz":-480,"elapsed":3812,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}},"outputId":"5f799993-8bfa-49dc-88f6-b60868f0c474"},"source":["#可以使用自定义层直接执行正向传播计算。\n","dense(torch.rand(2, 5))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.0000, 0.1683, 0.0000],\n","        [0.0000, 0.2254, 0.0000]])"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sa8WN3gJgSW1","executionInfo":{"status":"ok","timestamp":1619311837330,"user_tz":-480,"elapsed":4288,"user":{"displayName":"Liao Jack","photoUrl":"","userId":"16157886839679822522"}},"outputId":"0a61f118-b54a-4781-8363-4c9ce0e9e12b"},"source":["#可以使用自定义层构建模型。我们可以像使用内置的全连接层一样使用自定义层。\n","net = nn.Sequential(MyLinear(64, 8), MyLinear(8, 1))\n","net(torch.rand(2, 64))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[5.7780],\n","        [0.7684]])"]},"metadata":{"tags":[]},"execution_count":8}]}]}